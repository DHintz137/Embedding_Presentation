{
  "hash": "8251b85157149f139be55cfd3b7a40bf",
  "result": {
    "engine": "knitr",
    "markdown": "---\nwebr: \n  show-startup-message: false  \n  packages: ['tibble', 'dplyr', 'feather']\nformat:\n  revealjs:\n    include-in-header:\n      - file: js_scripts.html\n    theme: [default, theme.scss]\n    scrollable: true\n    css: styles.css\n    transition: slide\n    highlight-style: github\n    slide-number: true\n    sc-sb-title: true\n    logo: images/quarto.png\n    footer-logo-link: \"https://quarto.org\"\n    chalkboard: true\n    resources:\n      - British_National_Corpus_Vector_size_300_skipgram/model.bin\nbibliography: references.bib\ncsl: diabetologia.csl\nfilters: \n - webr\n - reveal-header\nslide-level: 4\nnumber-sections: false\nengine: knitr\n---\n\n\n# [An Exploration of Information Loss in Transformer Embedding Spaces for Enhancing Predictive AI in Genomics]{\n  style=\"color:#FFFFFF; \n         font-size: 55px; \n         position: relative;\n         bottom: 60px; \n         text-shadow: -1px -1px 0 #000, \n                      1px -1px 0 #000, \n                      -1px 1px 0 #000, \n                      1px 1px 0 #000;\"\n}{background-image=\"images/DALL_E_DNA_Image_edited.png\" background-size=\"cover\" background-color=\"#4f6952\"}\n\n\n<h1 style=\"color:#FFFFFF; \n         font-size: 28px; \n         text-align: center;\n         position: absolute; \n         top: 325px; \n         width: 100%; \n         text-shadow: -0.75px -0.75px 0 #000, \n                      0.75px -0.75px 0 #000, \n                      -0.75px 0.75px 0 #000, \n                      0.75px 0.75px 0 #000;\">Daniel Hintz <br> 2024-06-06</h2>\n\n\n## Thesis Question\n\n. . .\n\n::: {style=\"text-align:center; font-size: 0.85em;\"}\nHow easily can information be extracted from GenSLM embeddings while maintaining its original integrity; and what is the quality of the produced vector embeddings?\n:::\n\n\n::: {.notes}\n- The jargon won't have meaning now, will very soon, i.e.\n    - What is GenSLM\n    - What is an embedding \n    - Why do we care about the quality of an embedding \n    - What are real world applications  \n:::\n\n# [Outline]{style=\"font-size: 55px;\"} \n\n::: {style=\"font-size: 0.65em;\"}\n- Thesis Question\n- Background\n    - DNA\n    - Motivation\n    - GenSLM Embedding Algorithm \n- Data and Processing\n    - Source and Cleaning \n- Methodology\n    - Intrinsic and Extrinsic Evaluation\n- Results\n- Conclusion\n:::\n\n\n# [Background]{style=\"color:white;\"}{background-color=\"#8FA9C2\"}\n\n## DNA\n\n::: columns\n::: {.column width=\"80%\"}\n::: incremental\n::: {style=\"font-size: 0.6em;\"}\n- Deoxyribonucleic acid (DNA) is a molecule that contains the genetic code that provides the instructions for building and maintaining life.\n- The structure of DNA can be thought of as rungs on a ladder (known as base pairs) involving the pairing of four nucleotides - Adenine (A), Cytosine (C),Guanine (G) and Thymine (T).\n\n\n:::\n:::\n:::\n::: {.column width=\"20%\"}\n::: {style=\"text-align:center; font-size: 0.5em;\"}\n![Figure 1: DNA Base Pairs; [@NHGRI2024]](images/DNA_diagram.png)\n:::\n:::\n:::\n\n## DNA Sequencing Technology\n\n::: columns\n::: {.column width=\"50%\"}\n::: incremental\n::: {style=\"font-size: 0.6em;\"}\n- Someone gets tested for Covid, PCA is ran to detect if the assay is indeed positive.\n- Positive tests are sequenced using a machine that is most likely either Ilumina or Oxford Nanopore.\n- This takes in the Covid Sample and arrives at a digital copy of DNA sequences.\n:::\n:::\n:::\n::: {.column width=\"50%\"}\n::: {style=\"text-align:center; font-size: 0.5em;\"}\n![Figure 2: Simplified Schema of Sequencing Process for SARS-CoV-2](images/DNA_sequencing.png)\n:::\n:::\n:::\n\n\n## SARS-CoV-2 and Proteins\n\n::: columns\n::: {.column width=\"40%\"}\n::: incremental\n::: {style=\"font-size: 0.6em;\"}\n- SARS-CoV-2 has 29 proteins.\n- Different proteins have different functions.\n- Proteins are encoded from different sites of DNA.\n- In studying embeddings, tasks have been either **whole genome oriented** or **protein specific**. \n<!--\n- In the context of SARS-CoV-2, proteins are responsible for the virus's structure and infectivity.\n-  Nonstructural Proteins primarily function in the replication and manipulation of the host cell's environment to favor viral replication.\n-->\n:::\n:::\n:::\n::: {.column width=\"60%\"}\n::: {style=\"text-align:center; font-size: 0.5em;\"}\n![Figure 3: SARS-CoV-2 Proteins; Adapted from [@kandwal2023genetic], pg. 99](images/nsp1_str_non_str.png)\n:::\n:::\n:::\n\n## Mutations\n\n::: columns\n::: {.column width=\"40%\"}\n::: incremental\n::: {style=\"font-size: 0.6em;\"}\n- A mutation in the context of DNA refers to a change in the nucleotide sequence of the genetic material of an organism. \n- Mutations can be random or induced by external factors. \n- For contect, SARS-CoV-2 can mutate to become more infective for increasing its chances of survival.\n- There many different types of mutations but only substitutions are illustrated for this talk.\n::: \n::: \n:::\n::: {.column width=\"60%\"}\n::: {style=\"text-align:center; font-size: 0.5em;\"}\n![Figure 4: Substitution Mutations](images/mutation_example.png){width=\"45%\"}\n:::\n:::\n:::\n\n:::{.notes}\n- Spontaneous mutations: These arise naturally and randomly without any external influence, often due to errors in DNA replication. Errors might include mispairing of nucleotides or slippage during replication.\n- Induced mutations: These are caused by external factors, known as mutagens, which can include physical agents like ultraviolet light and X-rays, or chemical agents such as certain drugs and pollutants.\n\n**Why Mutations Occur**\n\nRandom errors: Many mutations result simply from random errors during DNA replication. DNA polymerase, the enzyme responsible for replicating DNA, is not perfect and occasionally makes mistakes.\n\nEnvironmental stress: Exposure to environmental stressors like radiation, chemicals, and even biological agents can damage DNA and lead to mutations.\n\nEvolutionary advantage: From an evolutionary perspective, mutations are a key mechanism of genetic variability and thus, evolution. While many mutations are neutral or harmful, some can confer advantages that lead to positive selection in a population.\n:::\n\n## Motivation \n\n::: incremental\n::: {style=\"font-size: 0.6em;\"}\n- This project came about from connecting with Nick Chia, a biophysicist at Argonne National labs.\n- Nick and his collaborators in 2020 (then at the Mayo Clinic) made an algorithm that predicted the trajectory of colorectal cancer mutations.\n- However, this algorithm was slow and expensive to train. \n- **The embeddings used in this algorithm was one of the biggest choke points**.\n- New and improved ways are needed to embed large genomes into lower dimensions\n    - For example, a one hot encoding for the human genome as DNA dimensionally is n x 3 billion x 4, where n is the number of patients, 3 billion is the number of rows for each nucleotide and 4 columns represent the four possible bases (A, T, G, C).\n- This is the **Big P little N problem**; hence dimension reduction via an embedding is extremely advantageous!\n- Further work needs to be done is studying the quality of embeddings to help bring about more efficient real world implementations like precision medicine for colorectal cancer. \n:::\n:::\n\n## Dimension Reduction \n\n::: {style=\"font-size: 0.6em;\"}\nIn the UW Statistics program what methods do we learn to apply dimension reduction?\n::: \n\n::: incremental\n::: {style=\"font-size: 0.6em;\"}\n- Principal component analysis (PCA)!\n- PCA as well as embeddings, transform the coordinate system of our data.\n- The difference for this project is that dimension reduction is being applied to DNA.\n::: \n::: \n\n## Embeddings\n\n::: incremental\n::: {style=\"font-size: 0.55em;\"}\n - An *embedding* is the name for the dense numeric vectors produced by *embedding algorithms*, such as GenSLM.\n \n -  \"Embedding\" generally refers to the embedding vector.\n \n -  Embeddings are representation of data in lower-dimensional space that preserves some aspects of the original structure of the data.\n\n- But why would you ever embed something?\n    - Embedding vectors are generally more computationally efficient.\n:::\n:::\n\n::: {.notes}\n- As an introduction, it will be easier to first walk through an example of an Embedding for natural language.\n:::\n\n\n## Sequence Embeddings\n\n::: incremental\n::: {style=\"font-size: 0.6em;\"}\n- Neural network embedding algorithms for genomic data include **GenSLM (the focus of this presentation)**, DNABERT2, and HyenaDNA.\n- These embeddings are lossy encodings, meaning that some information is lost in the transformation.\n- They also can distort structural relationships represented in the data.\n:::\n:::\n\n::: {.notes}\n- Just like we can represent words as vectors we can also represent genomic sequences as vectors.\n:::\n\n<!--\n## Why Data Representation Matters \n\n::: incremental\n::: {style=\"font-size: 0.6em;\"}\n- An embedding is one way of representing data.\n:::\n:::\n\n. . .\n\n::: {style=\"text-align:center; font-size: 0.5em;\"}\n![](images/pred_rep_obj.png){width=\"65%\"}\n:::\n\n::: {style=\"margin-top: 20px;\"}\n:::\n\n::: incremental\n::: {style=\"font-size: 0.6em;\"}\n-  An effective representation (embedding) of a genomic sequence is crucial for all downstream tasks.\n    - i.e., clustering, classification, regression, protein function identification, structural analysis, and predicting genetic disorders [@angermueller2016deep].\n- Given the increasing use of embeddings, embedding evaluation has also become more important. \n:::\n:::\n-->\n\n## GenSLM\n\n::: panel-tabset\n### Overview\n\n::: columns\n::: {.column width=\"40%\"}\n::: incremental\n::: {style=\"font-size: 0.6em;\"}\n- Overall, the GenSLM algorithm first **tokenizes**, i.e., breaks up sequences in to chunks of three nucleotides. \n- Then, the input sequence are **vectorized** creating a $1 \\times 512$ vector for each inputed sequence.\n:::\n:::\n:::\n::: {.column width=\"60%\"}\n::: {style=\"text-align:center; font-size: 0.5em;\"}\n![Figure 5: Generic Embedding Workflow](images/Tokenize_vectorize.png){width=\"50%\"}\n:::\n:::\n:::\n\n### Transformer\n::: columns\n::: {.column width=\"40%\"}\n::: incremental\n::: {style=\"font-size: 0.6em;\"}\n- First the tokenized input sequence is passed to the transformer encoder.\n- The transformer encoder converts 1,024 bp slices into numeric vectors. \n- This is ran recursively through a diffusion model to learn a condensed distribution of the whole sequence.\n- The transformers in GenSLM are used to capture local interactions within a genomic sequence.\n:::\n:::\n:::\n::: {.column width=\"60%\"}\n::: {style=\"text-align:center; font-size: 0.5em;\"}\n![Figure 6: GenSLM Transformer Architecture; [@genslms2023]](images/GenSLM.png)\n:::\n:::\n:::\n\n### Diffusion + Transformer\n\n\n\n::: incremental\n::: {style=\"font-size: 0.6em;\"}\n- Diffusion and Transformer models work in tandem in GenSLM.\n- Transformers captures local interactions, while the diffusion model captures learns a representation of transformers vectors to represent the whole genome.\n:::\n:::\n\n\n:::\n\n\n# [Downstream]{style=\"color:white;\"}{background-color=\"#8FA9C2\"}\n\n## Downstream\n\n::: incremental\n::: {style=\"font-size: 0.6em;\"}\n- Consider our colereactal cancer example, in the context of precision medicine, you may want to classify aggressive and non-aggressive cancers. \n\n- Or in the context of SARS-CoV-2, you may want to be able to monitor changes in variants and how they differ from previous variants. \n\n- Assuming embeddings in both examples, the tasks are considered **downstream** from the process of creating the embeddings from the original data. \n::: \n::: \n\n## Raw DNA versus embedded Data\n\n```{webr-r}\n#| context: setup\noptions(max.print = 10)\n# Download a dataset\n# url <- \"https://raw.githubusercontent.com/DHintz137/Embedding_Presentation/main/raw-data/variant_data_subset.feather\"\n# download.file(url, \"variant_data_subset.feather\")\n# Whole_genome_covid_seqs <- feather::read_feather(\"raw-data/variant_data_subset.feather\")\n```\n\n<!--\n# DT::datatable(Whole_genome_covid_seqs)\n-->\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<html>\n<div class=\"datatables html-widget html-fill-item\" id=\"htmlwidget-fc9496453d837b7ba89e\" style=\"width:100%;height:auto;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-fc9496453d837b7ba89e\">{\"x\":{\"filter\":\"none\",\"vertical\":false,\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\",\"34\",\"35\",\"36\",\"37\",\"38\",\"39\",\"40\",\"41\",\"42\",\"43\",\"44\",\"45\",\"46\",\"47\",\"48\",\"49\",\"50\",\"51\",\"52\",\"53\",\"54\",\"55\",\"56\",\"57\",\"58\",\"59\",\"60\",\"61\",\"62\",\"63\",\"64\",\"65\",\"66\",\"67\",\"68\",\"69\",\"70\",\"71\",\"72\",\"73\",\"74\",\"75\",\"76\",\"77\",\"78\",\"79\",\"80\",\"81\",\"82\",\"83\",\"84\",\"85\",\"86\",\"87\",\"88\",\"89\",\"90\",\"91\",\"92\",\"93\",\"94\",\"95\",\"96\",\"97\",\"98\",\"99\",\"100\",\"101\",\"102\",\"103\",\"104\",\"105\",\"106\",\"107\",\"108\",\"109\",\"110\",\"111\",\"112\",\"113\",\"114\",\"115\",\"116\",\"117\",\"118\",\"119\",\"120\",\"121\",\"122\",\"123\",\"124\",\"125\",\"126\",\"127\",\"128\",\"129\",\"130\",\"131\",\"132\",\"133\",\"134\",\"135\",\"136\",\"137\",\"138\",\"139\",\"140\",\"141\",\"142\",\"143\",\"144\",\"145\",\"146\",\"147\",\"148\",\"149\",\"150\"],[5.1,4.9,4.7,4.6,5,5.4,4.6,5,4.4,4.9,5.4,4.8,4.8,4.3,5.8,5.7,5.4,5.1,5.7,5.1,5.4,5.1,4.6,5.1,4.8,5,5,5.2,5.2,4.7,4.8,5.4,5.2,5.5,4.9,5,5.5,4.9,4.4,5.1,5,4.5,4.4,5,5.1,4.8,5.1,4.6,5.3,5,7,6.4,6.9,5.5,6.5,5.7,6.3,4.9,6.6,5.2,5,5.9,6,6.1,5.6,6.7,5.6,5.8,6.2,5.6,5.9,6.1,6.3,6.1,6.4,6.6,6.8,6.7,6,5.7,5.5,5.5,5.8,6,5.4,6,6.7,6.3,5.6,5.5,5.5,6.1,5.8,5,5.6,5.7,5.7,6.2,5.1,5.7,6.3,5.8,7.1,6.3,6.5,7.6,4.9,7.3,6.7,7.2,6.5,6.4,6.8,5.7,5.8,6.4,6.5,7.7,7.7,6,6.9,5.6,7.7,6.3,6.7,7.2,6.2,6.1,6.4,7.2,7.4,7.9,6.4,6.3,6.1,7.7,6.3,6.4,6,6.9,6.7,6.9,5.8,6.8,6.7,6.7,6.3,6.5,6.2,5.9],[3.5,3,3.2,3.1,3.6,3.9,3.4,3.4,2.9,3.1,3.7,3.4,3,3,4,4.4,3.9,3.5,3.8,3.8,3.4,3.7,3.6,3.3,3.4,3,3.4,3.5,3.4,3.2,3.1,3.4,4.1,4.2,3.1,3.2,3.5,3.6,3,3.4,3.5,2.3,3.2,3.5,3.8,3,3.8,3.2,3.7,3.3,3.2,3.2,3.1,2.3,2.8,2.8,3.3,2.4,2.9,2.7,2,3,2.2,2.9,2.9,3.1,3,2.7,2.2,2.5,3.2,2.8,2.5,2.8,2.9,3,2.8,3,2.9,2.6,2.4,2.4,2.7,2.7,3,3.4,3.1,2.3,3,2.5,2.6,3,2.6,2.3,2.7,3,2.9,2.9,2.5,2.8,3.3,2.7,3,2.9,3,3,2.5,2.9,2.5,3.6,3.2,2.7,3,2.5,2.8,3.2,3,3.8,2.6,2.2,3.2,2.8,2.8,2.7,3.3,3.2,2.8,3,2.8,3,2.8,3.8,2.8,2.8,2.6,3,3.4,3.1,3,3.1,3.1,3.1,2.7,3.2,3.3,3,2.5,3,3.4,3],[1.4,1.4,1.3,1.5,1.4,1.7,1.4,1.5,1.4,1.5,1.5,1.6,1.4,1.1,1.2,1.5,1.3,1.4,1.7,1.5,1.7,1.5,1,1.7,1.9,1.6,1.6,1.5,1.4,1.6,1.6,1.5,1.5,1.4,1.5,1.2,1.3,1.4,1.3,1.5,1.3,1.3,1.3,1.6,1.9,1.4,1.6,1.4,1.5,1.4,4.7,4.5,4.9,4,4.6,4.5,4.7,3.3,4.6,3.9,3.5,4.2,4,4.7,3.6,4.4,4.5,4.1,4.5,3.9,4.8,4,4.9,4.7,4.3,4.4,4.8,5,4.5,3.5,3.8,3.7,3.9,5.1,4.5,4.5,4.7,4.4,4.1,4,4.4,4.6,4,3.3,4.2,4.2,4.2,4.3,3,4.1,6,5.1,5.9,5.6,5.8,6.6,4.5,6.3,5.8,6.1,5.1,5.3,5.5,5,5.1,5.3,5.5,6.7,6.9,5,5.7,4.9,6.7,4.9,5.7,6,4.8,4.9,5.6,5.8,6.1,6.4,5.6,5.1,5.6,6.1,5.6,5.5,4.8,5.4,5.6,5.1,5.1,5.9,5.7,5.2,5,5.2,5.4,5.1],[0.2,0.2,0.2,0.2,0.2,0.4,0.3,0.2,0.2,0.1,0.2,0.2,0.1,0.1,0.2,0.4,0.4,0.3,0.3,0.3,0.2,0.4,0.2,0.5,0.2,0.2,0.4,0.2,0.2,0.2,0.2,0.4,0.1,0.2,0.2,0.2,0.2,0.1,0.2,0.2,0.3,0.3,0.2,0.6,0.4,0.3,0.2,0.2,0.2,0.2,1.4,1.5,1.5,1.3,1.5,1.3,1.6,1,1.3,1.4,1,1.5,1,1.4,1.3,1.4,1.5,1,1.5,1.1,1.8,1.3,1.5,1.2,1.3,1.4,1.4,1.7,1.5,1,1.1,1,1.2,1.6,1.5,1.6,1.5,1.3,1.3,1.3,1.2,1.4,1.2,1,1.3,1.2,1.3,1.3,1.1,1.3,2.5,1.9,2.1,1.8,2.2,2.1,1.7,1.8,1.8,2.5,2,1.9,2.1,2,2.4,2.3,1.8,2.2,2.3,1.5,2.3,2,2,1.8,2.1,1.8,1.8,1.8,2.1,1.6,1.9,2,2.2,1.5,1.4,2.3,2.4,1.8,1.8,2.1,2.4,2.3,1.9,2.3,2.5,2.3,1.9,2,2.3,1.8],[\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\"]],\"container\":\"<table class=\\\"cell-border stripe\\\">\\n  <thead>\\n    <tr>\\n      <th> <\\/th>\\n      <th>Sepal.Length<\\/th>\\n      <th>Sepal.Width<\\/th>\\n      <th>Petal.Length<\\/th>\\n      <th>Petal.Width<\\/th>\\n      <th>Species<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"pageLength\":4,\"dom\":\"tip\",\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[1,2,3,4]},{\"orderable\":false,\"targets\":0},{\"name\":\" \",\"targets\":0},{\"name\":\"Sepal.Length\",\"targets\":1},{\"name\":\"Sepal.Width\",\"targets\":2},{\"name\":\"Petal.Length\",\"targets\":3},{\"name\":\"Petal.Width\",\"targets\":4},{\"name\":\"Species\",\"targets\":5}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false,\"lengthMenu\":[4,10,25,50,100],\"rowCallback\":\"function(row, data, displayNum, displayIndex, dataIndex) {\\nvar value=data[1]; $(this.api().cell(row, 1).node()).css({'font-size':'10px'});\\nvar value=data[2]; $(this.api().cell(row, 2).node()).css({'font-size':'10px'});\\nvar value=data[3]; $(this.api().cell(row, 3).node()).css({'font-size':'10px'});\\nvar value=data[4]; $(this.api().cell(row, 4).node()).css({'font-size':'10px'});\\nvar value=data[5]; $(this.api().cell(row, 5).node()).css({'font-size':'10px'});\\n}\"},\"callback\":\"function(table) {\\ntable.columns().header().to$().css({'font-size': '10px'});\\n}\"},\"evals\":[\"options.rowCallback\",\"callback\"],\"jsHooks\":[]}</script>\n</html>\n```\n\n:::\n:::\n\n\n## Project Workflow\n\n::: {style=\"text-align:center; font-size: 0.5em;\"}\n![Figure 7: Project Workflow](images/Overall_workflow.png){width=\"30%\"}\n:::\n\n# [Data and Processing]{style=\"color:white;\"}{background-color=\"#8FA9C2\"}\n\n## Data Description\n\n\n::: incremental\n::: {style=\"font-size: 0.6em;\"}\n- All Covid sequences were downloaded with permission from the Global Initiative on Sharing All Influenza Data (GISAID).\n- No geographical or temporal restrictions were placed on the sequences extracted.\n:::\n:::\n\n## Data Cleaning \n\n::: incremental\n::: {style=\"font-size: 0.6em;\"}\n- GISAID's exclusion criteria was used to remove sequences of poor quality. \n- Additional exclusion criteria was implemented to remove all sequence with ambiguous nucleotides (the `NA's` of the genomic world) and large gap sizes post-alignment.\n:::\n:::\n\n\n## Multiple Sequence Alignment \n\n::: incremental\n::: {style=\"font-size: 0.6em;\"}\n- An multiple alignment alignment was performed to be able to slice the exact location of proteins across different sequences.\n:::\n::: \n\n. . .\n\n\n::: {style=\"text-align:center; font-size: 0.5em;\"}\n![Figure 18: Un-aligned Sequences](images/Unaligned_example.png){width=\"30%\"}\n:::\n. . .\n\n::: {style=\"text-align:center; font-size: 0.5em;\"}\n![Figure 19: Aligned Sequences](images/aligned_example.png){width=\"30%\"}\n:::\n\n\n\n# [Exploratory Data Analysis]{style=\"color:white;\"}{background-color=\"#8FA9C2\"}\n\n<!--\n## [What are the Patterns and Structures Oberved from the Sequence Data?]{style=\"font-size: 52px;\"}\n\n::: incremental\n::: {style=\"font-size: 0.6em;\"}\n- For Exploratory Data Analysis, the goal was the characterize the structure of the data in its sequence representation. \n-  This laid the groundwork for subsequent comparisons with the embedding structure.\n:::\n::: \n\n. . .\n\n::: {style=\"text-align:center; font-size: 0.5em;\"}\n![Figure 8: Mutation Boxplot](images/Whole_Genome_Mutation_Count_Hamming_Distances.png){width=\"50%\"}\n:::\n-->\n\n## \n\n::: {style=\"text-align:center; font-size: 0.5em;\"}\n![Figure 11: Hamming Distance of Aligned Proteins to Wuhan Reference Sequence](images/hamming_prot_heatmap_581_all_variants.png){width=\"100%\"}\n:::\n\n\n\n# [Methodology]{style=\"color:white;\"}{background-color=\"#8FA9C2\"}\n\n## Evaluating Embeddings \n\n::: incremental\n::: {style=\"font-size: 0.6em;\"}\n- Broadly speaking, the quality of an embedding is assessed based upon its information richness and the degree of non-redundancy.\n\n- Their are two main methodologies for evaluating embeddings: \n    - When downstream learning tasks are evaluated, it’s referred to as **extrinsic evaluation** [@lavravc2021representation].\n    - When the qualities of the embedding matrix itself are assessed it is referred to as **intrinsic evaluation** [@lavravc2021representation].\n:::\n:::\n\n## Intrinsic Evaluation\n\n::: incremental\n::: {style=\"font-size: 0.6em;\"}\n- There are three main qualities to asses when studying the the quality of an embedding: **Redundancy**, **Separability**, **Preservation of Semantic Distance**\n    - Redundancy reveals the efficiency of a embeddings encoding; more efficient encodings tend to perform better and use fewer computational resources.\n    - Separability gives practical insight into whether or not the embedding output can be separated into meaningful genomic groups (i.e., variants). \n    - Preservation of semantic distance is important for determining if the structural representation of information remains valid for subsequent tasks.\n\n- Sub-methods used for intrinsic evaluation include Singular Value Decomposition (SVD), Distance matrices, Radial Dendograms, and Principal Copnonent Analysis.\n:::\n:::\n\n## Extrinsic Evaluation\n\n::: incremental\n::: {style=\"font-size: 0.6em;\"}\n- Extrinsic evaluation pursues practical benchmarks to assess the performance of an embeddings algorithm per its associated embedding matrix across varying levels of task complexity.\n- For GenSLM, the subset of possible tasks chosen were variant and protein classification.\n- A Classification and Regression Tree (CART) was used for performing the classification.\n:::\n:::\n\n# [Results]{style=\"color:white;\"}{background-color=\"#8FA9C2\"}\n\n## [Intrinsic Evaluation Results]{style=\"color:#6FB1D1;\"}\n\n### [Redundancy]{style=\"color:#A9D0E3;\"}\n\n#### [Singular Value Decomposition]{style=\"font-size: 0.8em;\"}\n\n::: {style=\"text-align:center; font-size: 0.5em;\"}\n![Figure 13: SVD CPE Plot](images/SVD_582_cpe_2.png){width=\"92%\"}\n:::\n\n### [Preservation of Semantic Distance]{style=\"color:#A9D0E3;\"}\n\n#### Distance Matrices\n\n<!--X axis labels-->\n![](images/variant_labels/alpha.png){.absolute top=675 left=110 width=\"20.55\" height=\"16.91\"}\n![](images/variant_labels/beta.png){.absolute top=675 left=228 width=\"18.17\" height=\"29.48\"}\n![](images/variant_labels/delta.png){.absolute top=675 left=340 width=\"14.64\" height=\"24.91\"}\n![](images/variant_labels/epsilon.png){.absolute top=675 left=455 width=\"15.74\" height=\"21.83\"}\n![](images/variant_labels/gamma.png){.absolute top=675 left=575 width=\"20.07\" height=\"25.14\"}\n\n![](images/variant_labels/mu.png){.absolute top=675 left=692 width=\"20.71\" height=\"25.14\"}\n![](images/variant_labels/omicron.png){.absolute top=675 left=815 width=\"21.45\" height=\"22.91\"}\n\n<!--Y axis labels-->\n\n![](images/variant_labels/alpha_90degrees.png){.absolute top=630 left=37.5 width=\"16.91\" height=\"20.55\"}\n![](images/variant_labels/beta_90degrees.png){.absolute top=580 left=32 width=\"29.48\" height=\"18.17\"}\n\n\n![](images/variant_labels/delta_90degrees.png){.absolute top=538 left=32 width=\"24.91\" height=\"14.64\"}\n\n![](images/variant_labels/epsilon_90degrees.png){.absolute top=490 left=32 width=\"21.83\" height=\"15.74\"}\n\n![](images/variant_labels/gamma_90degrees.png){.absolute top=440 left=32 width=\"25.14\" height=\"20.07\"}\n\n![](images/variant_labels/mu_90degrees.png){.absolute top=390 left=32 width=\"25.14\" height=\"20.71\"}\n\n![](images/variant_labels/omicron_90degrees.png){.absolute top=340 left=32 width=\"22.91\" height=\"21.45\"}\n\n\n\n::: panel-tabset\n##### Sequence \n::: {style=\"margin-top: 0px;\"}\n:::\n\n::: {style=\"font-size: 0.6em;\"}\n- There is a lot of heterogeneity in the differences among sequences as fine scales. \n- Notice the L shape in striations in alpha sequences compare to other variants. \n:::\n\n<iframe class=\"plotlyFrame\" src=\"./seq_dist_matrix.html\" style=\"border: none;\"></iframe>\n\n##### Embeddings \n::: {style=\"margin-top: 5.5px;\"}\n:::\n\n::: {style=\"font-size: 0.6em;\"}\n- Comparing the Sequence distance matrix to the Embedding distance matrix we see that finer differences amongst sequences are lost in the embedding transformation. \n:::\n\n<iframe class=\"plotlyFrame\" src=\"./emb_dist_matrix.html\" style=\"border: none;\"></iframe>\n\n##### Abs. Diff.\n::: {style=\"margin-top: 5px;\"}\n:::\n\n::: {style=\"font-size: 0.6em;\"}\n- The absolute difference matrix is the absolute difference of the sequence distance matrix and the embedding distance matrix.\n:::\n\n<iframe class=\"plotlyFrame\" src=\"./abs_diff_dist_matrix.html\" style=\"border: none;\"></iframe>\n\n##### Reg. Diff.\n::: {style=\"margin-top: 18px;\"}\n:::\n\n::: {style=\"font-size: 0.6em;\"}\n- The difference distance matrix is the sequence distance matrix minus the embedding distance matrix.\n:::\n\n::: {style=\"margin-top: 18px;\"}\n:::\n\n<iframe class=\"plotlyFrame\" src=\"./diff_dist_matrix.html\" style=\"border: none;\"></iframe>\n\n:::\n\n\n\n\n#### Radial Dendrograms (1)\n\n::: incremental\n::: {style=\"font-size: 0.6em;\"}\n- Radial dendrograms show who easily sequences cluster by their variant.\n- Figures 12 and 13 in the next two slides show:\n    - Radial dendrograms using sequence data does not perfectly clusters sequences by variants. \n    - Radial dendrograms using the embedded data perfectly clusters sequences by variants. \n:::\n::: \n\n#### Radial Dendrograms (2)\n\n![](images/Radial_dendrograms.png)\n\n\n### [Separability]{style=\"color:#A9D0E3;\"}\n\n### Principal Component Analysis\n\n::: {style=\"margin-top: 70px;\"}\n:::\n\n<iframe class=\"plotlyFrame\" src=\"./v_pc_plotly.html\" style=\"border: none;\"></iframe>\n\n\n## [Extrinsic Evaluation Results]{style=\"color:#6FB1D1;\"}\n\n### [Variant Classification]{style=\"color:#A9D0E3;\"}\n\n#### [Variant Embedding Classification (1)]{style=\"font-size: 0.8em;\"}\n\n::: incremental\n::: {style=\"font-size: 0.5em;\"}\n- Variant classification with a CART learner had a 97.71% on aligned sequence embeddings.\n:::\n:::\n\n. . .\n\n\n![Figure 17: Variant Missclassifcations](images/Variant_CART_tree.png){width=\"67%\"}\n\n#### Variant Embedding Classification (2)\n\n::: {style=\"text-align:center; font-size: 0.5em;\"}\n![Figure 17: Variant Missclassifcations](images/Variant_missclassifcations.png){width=\"40%\"}\n:::\n\n\n#### Variant One-Hot-Encoding Classification\n\n\n. . .\n\n::: incremental\n::: {style=\"font-size: 0.6em;\"}\n- Variant classification with a CART learner had a 10.28% on One-Hot-Encoded sequences.\n:::\n:::\n\n. . .\n\n\n\n{{< pdf images/CART_variant_binary_cropped.pdf width=900 height=400 >}}\n\n\n\n:::{.notes}\n-  one-hot encoding Covid sequences (assuming all sequences are of length 30,000) creates a one dimensional array of $n \\times 30,000 \\times 4$, 4 columns representing 4 different bases\n\n- A: \\([1, 0, 0, 0]\\)\n- C: \\([0, 1, 0, 0]\\)\n- G: \\([0, 0, 1, 0]\\)\n- T: \\([0, 0, 0, 1]\\)\n\nwhere a there is 30,000 rows to represent all 30,000 nucleotides in a Covid sequence; thus with n matrices of $30,000 \\times 4$ comprising the multidimensional array for each patient (ie each whole genome sequence)\n::: \n\n<!--\n### Protein Classification\n\n. . .\n\n::: panel-tabset\n#### Embedding\n\n\n::: {style=\"font-size: 0.5em;\"}\n- 100% classification rate using the all 512 dimensions from the GenSLM embedding.\n:::\n\n\n\n{{< pdf images/protein_CART.gv.pdf width=900 height=400 >}}\n\n\n\n#### PCA Reduced Embedding\n\n::: {style=\"font-size: 0.5em;\"}\n- 100% classification rate using the PCA reduced feature matrix with 28 dimensions.\n:::\n\n\n\n{{< pdf images/protein_CART_29_PCA_components.gv.pdf width=900 height=400 >}}\n\n\n:::\n-->\n\n## Thesis Question\n\n::: {style=\"text-align:center; font-size: 0.85em;\"}\nHow easily can information be extracted from GenSLM embeddings while maintaining its original integrity; and what is the quality of the produced vector embeddings?\n:::\n\n## Conclusion\n::: incremental\n::: {style=\"font-size: 0.6em;\"}\n- The study assessed GenSLM's embeddings for quality using intrinsic and extrinsic evaluations, focusing on redundancy, separability, and information preservation.\n- GenSLM demonstrated strong performance in classification tasks, with a 97.71% success rate for variant classification and 100% for proteins using the CART learner, significantly outperforming One-Hot-Encoded matrices.\n- While GenSLM excelled in separability, it showed less effectiveness in preserving fine-scale genetic differences and distorted the genetic distances between certain viral variants.\n- The embeddings displayed considerable dimensional redundancy and only moderate success in preserving semantic distances, indicating areas for improvement.\n- Future research should compare GenSLM with other neural network embedding algorithms and explore its utility in more diverse genomic analysis tasks to establish broader applicability.\n:::\n:::\n\n# [Thank you!!]{.center style=\"color:white;\"}{background-color=\"#8FA9C2\"}\n\n# [Appendix]{style=\"color:white;\"}{background-color=\"#8FA9C2\"}\n\n#\n\n\n{{< pdf DHintz_PlanB_Submission.pdf width=1000 height=650 >}}\n\n\n\n# `<svg aria-hidden=\"true\" role=\"img\" viewBox=\"0 0 576 512\" style=\"height:1em;width:1.12em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:white;overflow:visible;position:relative;\"><path d=\"M163.9 136.9c-29.4-29.8-29.4-78.2 0-108s77-29.8 106.4 0l17.7 18 17.7-18c29.4-29.8 77-29.8 106.4 0s29.4 78.2 0 108L310.5 240.1c-6.2 6.3-14.3 9.4-22.5 9.4s-16.3-3.1-22.5-9.4L163.9 136.9zM568.2 336.3c13.1 17.8 9.3 42.8-8.5 55.9L433.1 485.5c-23.4 17.2-51.6 26.5-80.7 26.5H192 32c-17.7 0-32-14.3-32-32V416c0-17.7 14.3-32 32-32H68.8l44.9-36c22.7-18.2 50.9-28 80-28H272h16 64c17.7 0 32 14.3 32 32s-14.3 32-32 32H288 272c-8.8 0-16 7.2-16 16s7.2 16 16 16H392.6l119.7-88.2c17.8-13.1 42.8-9.3 55.9 8.5zM193.6 384l0 0-.9 0c.3 0 .6 0 .9 0z\"/></svg>`{=html} [Acknowledgements]{style=\"color:white; font-size: 70px;\"} {background-color=\"#8FA9C2\"}\n\n::: incremental\n- Committee members \n- Cohort\n:::\n\n\n## Word Embeddings \n\n::: incremental\n::: {style=\"font-size: 0.6em;\"}\n- Before we introduce GenSLM, lets look at a simpler application in natural language.\n    - If we consider English text, **How can we measure the similarity between words?**\n    - For example, what is the semantic difference between the words \"King\" and \"Woman\".\n    - Let's demonstrate the semantic relationships of “King”, “Queen”, “Man”, “Woman”.\n:::\n:::\n\n::: {.notes}\n- Embedding algorithms need data (a corpus of text) to construct numeric vectors relating words and their meaning.\n:::\n\n\n## Word2vec Example\n\n. . .\n\n```{webr-r}\n#| context: setup\n\noptions(max.print = 15)\n# Download a dataset\nurl <- \"https://raw.githubusercontent.com/DHintz137/Embedding_Presentation/main/raw-data/King_Man_Woman_Queen_pred.csv\"\ndownload.file(url, \"King_Man_Woman_Queen_pred.csv\")\nembedding_raw <- read.csv(\"King_Man_Woman_Queen_pred.csv\")\nembedding <- t(data.frame(embedding_raw[,-1] ,row.names = embedding_raw[,1]))\ncolnames(embedding) <- c(\"King\", \"Man\", \"Woman\", \"Queen\")\n# embedding <- as_tibble(embedding)\n\nprint_tidy <- function(x, ...) {\n  if (is.matrix(x) || length(dim(x)) > 1) {\n    # If x is a matrix or array, convert each column into a tibble column\n    out <- as_tibble(as.data.frame(x))\n  } else if (is.vector(x)) {\n    # If x is a vector, convert it into a single column tibble\n    out <- tibble(value = x)\n  } else {\n    # Fallback for other data types\n    out <- as_tibble(x)\n  }\n  print(out, ...)\n}\n```\n\n\n\n::: {.cell .small-code}\n\n```{.r .small-code .cell-code}\n## Pre-Ran Code ##\nlibrary(word2vec)\n# using British National Corpus http://vectors.nlpl.eu/repository/\nmodel <- read.word2vec(\"British_National_Corpus_Vector_size_300_skipgram\", normalize = TRUE)\nembedding <- predict(model,newdata = c(\"king_NOUN\",\"man_NOUN\",\"woman_NOUN\",\"queen_NOUN\"),type=\"embedding\")\n```\n:::\n\n\n\n::: {style=\"margin-top: 20px;\"}\n:::\n\n. . .\n\n```{webr-r}\n#| class-source: small-code\n#| classes: small-code\nprint_tidy(embedding)\nprint_tidy(embedding[ ,\"King\"] - embedding[ , \"Man\"] + embedding[ , \"Woman\"])\nprint_tidy(t(embedding[ , \"Man\"]) %*% embedding[ , \"Woman\"])\n```\n\n## Plotting Word Embeddings\n\n. . .\n\n::: {style=\"font-size: 0.6em;\"}\n- We can Plot the vectors shown in the previous slide to demonstrate how word2vec produces embeddings that measures semantic similarity between words. \n:::\n\n. . .\n\n::: {style=\"text-align:center; font-size: 0.5em;\"}\n![Figure 4: Word Embedding Vectors ](images/King_Man_Woman_Queen.png){width=\"70%\"}\n:::\n\n\n#### Kullback–Leibler Divergence (KLD)\n::: {style=\"text-align:center; font-size: 0.5em;\"}\n![Figure 15: CKL vs DKL](images/CKL_vs_DKL_ver2.png){width=\"85%\"}\n:::\n\n# [References]{.center style=\"color:#464D58;\"}{background-color=\"#8FA9C2\"}\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"index_files/libs/htmltools-fill-0.5.8.1/fill.css\" rel=\"stylesheet\" />\n<script src=\"index_files/libs/htmlwidgets-1.6.4/htmlwidgets.js\"></script>\n<link href=\"index_files/libs/datatables-css-0.0.0/datatables-crosstalk.css\" rel=\"stylesheet\" />\n<script src=\"index_files/libs/datatables-binding-0.33/datatables.js\"></script>\n<script src=\"index_files/libs/jquery-3.6.0/jquery-3.6.0.min.js\"></script>\n<link href=\"index_files/libs/dt-core-1.13.6/css/jquery.dataTables.min.css\" rel=\"stylesheet\" />\n<link href=\"index_files/libs/dt-core-1.13.6/css/jquery.dataTables.extra.css\" rel=\"stylesheet\" />\n<script src=\"index_files/libs/dt-core-1.13.6/js/jquery.dataTables.min.js\"></script>\n<link href=\"index_files/libs/crosstalk-1.2.1/css/crosstalk.min.css\" rel=\"stylesheet\" />\n<script src=\"index_files/libs/crosstalk-1.2.1/js/crosstalk.min.js\"></script>\n"
      ],
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}